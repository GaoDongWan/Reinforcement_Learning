{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DQN_TF.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hB-PL2kOuMhx","colab_type":"text"},"source":["### **装载云盘**"]},{"cell_type":"code","metadata":{"id":"W3kk56zyuKF8","colab_type":"code","outputId":"a32024a0-1f15-4b23-9859-d97af8a47673","executionInfo":{"status":"ok","timestamp":1567470843597,"user_tz":-480,"elapsed":57772,"user":{"displayName":"Steven Iris","photoUrl":"","userId":"04172472830736813201"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ipnfS2Csyu33","colab_type":"text"},"source":["### **安装tensorflow 2.0**"]},{"cell_type":"code","metadata":{"id":"49C0mzzby3s_","colab_type":"code","outputId":"8463a723-38e1-4e09-d9a0-ec8cbb35ba3e","executionInfo":{"status":"ok","timestamp":1567471021250,"user_tz":-480,"elapsed":51883,"user":{"displayName":"Steven Iris","photoUrl":"","userId":"04172472830736813201"}},"colab":{"base_uri":"https://localhost:8080/","height":541}},"source":["!pip install tensorflow-gpu==2.0.0-beta1 "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==2.0.0-beta1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/53/e18c5e7a2263d3581a979645a185804782e59b8e13f42b9c3c3cfb5bb503/tensorflow_gpu-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (348.9MB)\n","\u001b[K     |████████████████████████████████| 348.9MB 69kB/s \n","\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.2.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (3.7.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.33.6)\n","Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow-gpu==2.0.0-beta1)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n","\u001b[K     |████████████████████████████████| 501kB 39.3MB/s \n","\u001b[?25hCollecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow-gpu==2.0.0-beta1)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 29.5MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.7.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.1.7)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.8.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.16.4)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.0.8)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.11.2)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-beta1) (41.2.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (0.15.5)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.1.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta1) (2.8.0)\n","Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n","Successfully installed tb-nightly-1.14.0a20190603 tensorflow-gpu-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SOpdHh4dAK0w","colab_type":"code","outputId":"28c0d192-7e6d-40d1-8473-0de62e97b0aa","executionInfo":{"status":"ok","timestamp":1567471028701,"user_tz":-480,"elapsed":57510,"user":{"displayName":"Steven Iris","photoUrl":"","userId":"04172472830736813201"}},"colab":{"base_uri":"https://localhost:8080/","height":559}},"source":["# tensorlayer 兼容问题\n","!pip install imgaug==0.2.6"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting imgaug==0.2.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n","\r\u001b[K     |▌                               | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.6) (1.3.1)\n","Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.6) (0.15.0)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.6) (1.16.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.6) (1.12.0)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (4.3.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2.3)\n","Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2.4.1)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (3.0.3)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (1.0.3)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image>=0.11.0->imgaug==0.2.6) (0.46)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.6) (4.4.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (2.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (1.1.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (2.5.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (41.2.0)\n","Building wheels for collected packages: imgaug\n","  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=ff6c6ce83dbd160ab176138f1b7d6f6211483d7228d9888aaf22691a6f684b0d\n","  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n","Successfully built imgaug\n","Installing collected packages: imgaug\n","  Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","Successfully installed imgaug-0.2.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nDeaUCyG_kbP","colab_type":"code","outputId":"7d7d2735-c12e-4518-de45-63897d53ee6f","executionInfo":{"status":"ok","timestamp":1567471047288,"user_tz":-480,"elapsed":74204,"user":{"displayName":"Steven Iris","photoUrl":"","userId":"04172472830736813201"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install tensorlayer"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting tensorlayer\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/7d/80daea9f4359253b76266bc3d4ebd665b5a56eab4117a96d60e63f2182cb/tensorlayer-2.1.0-py2.py3-none-any.whl (353kB)\n","\r\u001b[K     |█                               | 10kB 14.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy<1.17,>=1.16 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (1.16.4)\n","Requirement already satisfied: scikit-image==0.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (0.15.0)\n","Collecting wrapt==1.11.1 (from tensorlayer)\n","  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n","Collecting h5py>=2.9 (from tensorlayer)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n","\u001b[K     |████████████████████████████████| 2.8MB 38.3MB/s \n","\u001b[?25hCollecting scipy==1.2.1 (from tensorlayer)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n","\u001b[K     |████████████████████████████████| 24.8MB 1.9MB/s \n","\u001b[?25hRequirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (2.21.0)\n","Collecting cloudpickle>=0.8.1 (from tensorlayer)\n","  Downloading https://files.pythonhosted.org/packages/09/f4/4a080c349c1680a2086196fcf0286a65931708156f39568ed7051e42ff6a/cloudpickle-1.2.1-py2.py3-none-any.whl\n","Collecting imageio==2.5.0 (from tensorlayer)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0a/943c965d372dae0b1f1482677d29030ab834351a61a9a632fd62f27f1523/imageio-2.5.0-py3-none-any.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 32.1MB/s \n","\u001b[?25hCollecting scikit-learn==0.21.0 (from tensorlayer)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/6c/ec121123c671d980c6969dfc69d0f09e1d7f88d80d373f511e61d773b85c/scikit_learn-0.21.0-cp36-cp36m-manylinux1_x86_64.whl (6.6MB)\n","\u001b[K     |████████████████████████████████| 6.6MB 25.2MB/s \n","\u001b[?25hCollecting progressbar2==3.39.3 (from tensorlayer)\n","  Downloading https://files.pythonhosted.org/packages/fb/89/d90f9ff03285d8eb56994e8cec1b73a4d0dc9bb529c1f8e8e10b1b663843/progressbar2-3.39.3-py2.py3-none-any.whl\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.15.0->tensorlayer) (4.3.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.15.0->tensorlayer) (2.3)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.15.0->tensorlayer) (3.0.3)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.15.0->tensorlayer) (1.0.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py>=2.9->tensorlayer) (1.12.0)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->tensorlayer) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->tensorlayer) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->tensorlayer) (2019.6.16)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->tensorlayer) (1.24.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.0->tensorlayer) (0.13.2)\n","Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2==3.39.3->tensorlayer) (2.3.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image==0.15.0->tensorlayer) (0.46)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image==0.15.0->tensorlayer) (4.4.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->tensorlayer) (2.4.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->tensorlayer) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->tensorlayer) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->tensorlayer) (2.5.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->tensorlayer) (41.2.0)\n","Building wheels for collected packages: wrapt\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.11.1-cp36-cp36m-linux_x86_64.whl size=67431 sha256=7f661193938ecca5122bf622d391f26d4640704e6a2e89f53a0f3aaf6a4235aa\n","  Stored in directory: /root/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n","Successfully built wrapt\n","Installing collected packages: wrapt, h5py, scipy, cloudpickle, imageio, scikit-learn, progressbar2, tensorlayer\n","  Found existing installation: wrapt 1.11.2\n","    Uninstalling wrapt-1.11.2:\n","      Successfully uninstalled wrapt-1.11.2\n","  Found existing installation: h5py 2.8.0\n","    Uninstalling h5py-2.8.0:\n","      Successfully uninstalled h5py-2.8.0\n","  Found existing installation: scipy 1.3.1\n","    Uninstalling scipy-1.3.1:\n","      Successfully uninstalled scipy-1.3.1\n","  Found existing installation: cloudpickle 0.6.1\n","    Uninstalling cloudpickle-0.6.1:\n","      Successfully uninstalled cloudpickle-0.6.1\n","  Found existing installation: imageio 2.4.1\n","    Uninstalling imageio-2.4.1:\n","      Successfully uninstalled imageio-2.4.1\n","  Found existing installation: scikit-learn 0.21.3\n","    Uninstalling scikit-learn-0.21.3:\n","      Successfully uninstalled scikit-learn-0.21.3\n","  Found existing installation: progressbar2 3.38.0\n","    Uninstalling progressbar2-3.38.0:\n","      Successfully uninstalled progressbar2-3.38.0\n","Successfully installed cloudpickle-1.2.1 h5py-2.9.0 imageio-2.5.0 progressbar2-3.39.3 scikit-learn-0.21.0 scipy-1.2.1 tensorlayer-2.1.0 wrapt-1.11.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cloudpickle"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"wgNs2Gd10f73","colab_type":"text"},"source":["### **cd命令**"]},{"cell_type":"code","metadata":{"id":"BBQU9lh_yls5","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"drive/My Drive/RL_EA/Deep_Q_Network\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3TpgOs8f0lUO","colab_type":"text"},"source":["### **查看当前路径**"]},{"cell_type":"code","metadata":{"id":"c21teJ570bmB","colab_type":"code","outputId":"02c5d60e-e530-40cc-e33a-2b52d05a4f01","executionInfo":{"status":"ok","timestamp":1567423555542,"user_tz":-480,"elapsed":5899,"user":{"displayName":"Steven Iris","photoUrl":"","userId":"04172472830736813201"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!pwd"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/RL_EA/Deep_Q_Network\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kWi3CPrl1q79","colab_type":"text"},"source":["# Deep Q Network\n","\n","$$\n","off-Policy\\\\\n","discrete\n","$$ \n","\n","两个特点：\n","\n","1）从 $Experience Replay Memory$ 中均匀采样。为了消除样本相关性。\n","\n","2）延迟复制权值的 $Fixed Q-target$ 网络。提高稳定性，收敛性，消除估计$Q$和目标$Q$的相关性。\n","\n","回顾$Q-Learning$的更新过程:\n","\n","$$\n","Q(s,a)=Q(s,a)+\\alpha\\big[r+\\gamma\\max_{a'}Q(s',a')-Q(s,a)\\big]\n","$$\n","\n","可以看到$Q-Learning$就是让$Q$值接近目标$Q$值，那么$DQN$的$loss$：\n","\n","$$\n","targetQ\\:or\\:y'=r + \\gamma \\max_{a'} Q(s',a';\\theta_i^-)\n","$$\n","$$\n","L_i(\\theta_i) = \\mathbb{E}_{(s,a,r,s') \\sim U(D)} \\big[ \\big( r + \\gamma \\max_{a'} Q(s',a';\\theta_i^-) - Q(s, a; \\theta_i) \\big)^2 \\big]\n","$$\n","\n","## DQN的变种：\n","\n","### Double DQN：\n","$$\n","Y_t^{DoubleQ} = R_{t+1} + \\gamma  Q(S_{t+1}, \\arg\\max_a Q(S_{t+1}, a; \\theta_t); \\theta_t)\n","$$\n","减少过估计带来的影响。\n","\n","### Dueling DQN：\n","$$\n","Q(s, a; \\theta, \\alpha, \\beta) = V (s; \\theta, \\beta) + \\big( A(s, a; \\theta, \\alpha) - \\frac{1}{|\\mathcal{A}|} \\sum_{a'} A(s, a'; \\theta, \\alpha) \\big)\n","$$\n","同一个网络输出状态值和优势值。\n","\n","### Prioritized ER: \n","\n","是改进效果最好的一个DQN变种。按照 $\\delta_i=TD-error$ 的值的大小对ER中的经验进行排序，每个经验的概率为\n","\n","$$\n","P(i) = \\frac{p_i^{\\alpha}}{\\sum_k p_k^{\\alpha}}\n","$$\n","\n","其中 $p_i = |\\delta_i| + \\epsilon$。考虑到不能只学$P(i)$大的样本，导致过拟合，因此对其进行加权：\n","\n","$$\n","w_i = \\big( \\frac{1}{N} \\cdot \\frac{1}{P(i)} \\big)^\\beta\n","$$\n","\n","### Noisy DQN：\n","对网络中的某些（或全部）权值加上noise。也是为了防过拟合，过相关。\n","\n"]},{"cell_type":"code","metadata":{"id":"jFR7KnkqxMy-","colab_type":"code","colab":{}},"source":["# 实现prioritized+DQN\n","import time\n","import os\n","import random\n","import operator\n","\n","import numpy as np\n","\n","import gym\n","import tensorflow as tf\n","import tensorlayer as tl\n","from tutorial_wrappers import build_env\n","\n","random.seed(0)\n","np.random.seed(0)\n","tf.random.set_seed(0)\n","\n","ENV_NAME = 'PongNoFrameskip-v4'  # PongNoFrameskip-v4 or CartPole-v0\n","env = build_env(ENV_NAME)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EhurBgWjYqPH","colab":{}},"source":["### hyper ###\n","\n","if ENV_NAME == 'CartPole-v0':\n","  qnet_type = 'MLP'\n","  number_timesteps = 10000\n","  explore_timesteps = 100\n","  # 利用率从0.01 -> 0.99\n","  epsilon = lambda i_iter: 1 - 0.99 * min(1, i_iter / explore_timesteps)\n","  lr = 5e-3\n","  buffer_size = 1000\n","  target_q_update_freq = 50\n","  ob_scale = 1.0\n","else:\n","  qnet_type = 'CNN'\n","  number_timesteps = int(1e6)\n","  explore_timesteps = 1e5\n","  # 利用率从0.01 -> 0.99\n","  epsilon = lambda i_iter: 1 - 0.99 * min(1, i_iter / explore_timesteps)\n","  lr = 1e-4\n","  buffer_size = 10000\n","  target_q_update_freq = 200\n","  ob_scale = 1.0 / 255\n","\n","in_dim = env.observation_space.shape\n","out_dim = env.action_space.n\n","reward_gamma = 0.99\n","batch_size = 32\n","warm_start = buffer_size / 10\n","prioritized_replay_alpha = 0.6\n","prioritized_replay_beta0 = 0.4"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ubTvO_ekY3g-","colab_type":"text"},"source":["### **网络框架**"]},{"cell_type":"code","metadata":{"id":"C3v7rblzY7LP","colab_type":"code","colab":{}},"source":["# 动态构建网络方式\n","class MLP(tl.models.Model):\n","\n","  def __init__(self, name):\n","    super(MLP, self).__init__(name=name)\n","    self.h1 = tl.layers.Dense(64, tf.nn.tanh, in_channels=in_dim[0])\n","    self.qvalue = tl.layers.Dense(out_dim, in_channels=64, name='q', W_init=tf.initializers.GlorotUniform())\n","\n","  def forward(self, ni):\n","    return self.qvalue(self.h1(ni))\n","\n","\n","class CNN(tl.models.Model):\n","\n","  def __init__(self, name):\n","    super(CNN, self).__init__(name=name)\n","    h, w, in_channels = in_dim\n","    dense_in_channels = 64 * ((h - 28) // 8) * ((w - 28) // 8)\n","    self.conv1 = tl.layers.Conv2d(\n","        32, (8, 8), (4, 4), tf.nn.relu, 'VALID', in_channels=in_channels, name='conv2d_1',\n","        W_init=tf.initializers.GlorotUniform()\n","    )\n","    self.conv2 = tl.layers.Conv2d(\n","        64, (4, 4), (2, 2), tf.nn.relu, 'VALID', in_channels=32, name='conv2d_2',\n","        W_init=tf.initializers.GlorotUniform()\n","    )\n","    self.conv3 = tl.layers.Conv2d(\n","        64, (3, 3), (1, 1), tf.nn.relu, 'VALID', in_channels=64, name='conv2d_3',\n","        W_init=tf.initializers.GlorotUniform()\n","    )\n","    # 展开成vector\n","    self.flatten = tl.layers.Flatten(name='flatten')\n","    self.preq = tl.layers.Dense(\n","        256, tf.nn.relu, in_channels=dense_in_channels, name='pre_q', W_init=tf.initializers.GlorotUniform()\n","    )\n","    self.qvalue = tl.layers.Dense(out_dim, in_channels=256, name='q', W_init=tf.initializers.GlorotUniform())\n","\n","  def forward(self, ni):\n","    feature = self.flatten(self.conv3(self.conv2(self.conv1(ni))))\n","    return self.qvalue(self.preq(feature))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vs_SZwfGhMhD","colab_type":"text"},"source":["### **$Priorizised\\ \\ ER$ 用到的线段树结构**"]},{"cell_type":"code","metadata":{"id":"NyyGM2XWhihU","colab_type":"code","colab":{}},"source":["class SegmentTree:\n","\n","  def __init__(self, capacity, operation, neutral_element):\n","    \"\"\"\n","    capacity: array的size，2的幂\n","    operation: 整合elements的操作\n","    neutral_element: 对上述操作的边界element\n","    \"\"\"\n","    assert capacity > 0 and capacity & (capacity - 1) == 0,\\\n","    \"capacity must be positive and a power of 2\"\n","    self._capacity = capacity\n","    # 完全二叉树的结构存储数据，叶子节点是数据值（这里是优先权重P）\n","    self._value = [neutral_element for _ in range(2 * capacity)]\n","    self._operation = operation\n","\n","  def _reduce_helper(self, start, end, node, node_start, node_end):\n","    # logN 操作复杂度\n","    if start == node_start and end == node_end:\n","      return self._value[node]\n","    mid = (node_start + node_end) // 2\n","    if end <= mid:\n","      return self._reduce_helper(start, end, 2 * node, node_start, mid)\n","    else:\n","      if mid + 1 <= start:\n","        return self._reduce_helper(start, end, 2 * node + 1, mid + 1, node_end)\n","      else:\n","        return self._operation(\n","            self._reduce_helper(start, mid, 2 * node, node_start, mid),\n","            self._reduce_helper(mid + 1, end, 2 * node + 1, mid + 1, node_end)\n","        )\n","  \n","  def reduce(self, start=0, end=None):\n","    \"\"\"\n","    返回一个邻近子区间array\n","    \"\"\"\n","    if end is None:\n","      end = self._capacity\n","    if end < 0:\n","      end += self._capacity #???\n","    end -= 1\n","    return self._reduce_helper(start, end, 1, 0, self._capacity - 1)\n","\n","  def __setitem__(self, idx, val):\n","    # 叶子的index，类似java的get，set，这样做可以直接用数组形式访问。\n","    idx += self._capacity\n","    self._value[idx] = val\n","    idx //= 2\n","    while idx >= 1:\n","      self._value[idx] = self._operation(self._value[2 * idx], self._value[2 * idx + 1])\n","      idx //= 2\n","\n","  def __getitem__(self, idx):\n","    assert 0 <= idx < self._capacity\n","    return self._value[self._capacity + idx]\n","\n","# Sum 线段树\n","class SumSegmentTree(SegmentTree):\n","\n","  def __init__(self, capacity):\n","    super(SumSegmentTree, self).__init__(capacity=capacity, operation=operator.add, neutral_element=0.0)\n","\n","  def sum(self, start=0, end=None):\n","    \"\"\"\n","    return: arr[start]+...+arr[end]\n","    \"\"\"  \n","    return super(SumSegmentTree, self).reduce(start, end)\n","\n","  def find_prefixsum_idx(self, prefixsum):\n","    \"\"\"\n","    找到最大的index i，满足sum(arr[0]+...+arr[i-1]<=prefixsum)\n","\n","    如果array里是概率，这个函数可以从离散概率中sample index\n","    \n","    prefixsum: 之前的elements的和的上界\n","    \"\"\"\n","    assert 0 <= prefixsum <= self.sum() + 1e-5\n","    idx = 1\n","    while idx < self._capacity:\n","      if self._value[2 * idx] > prefixsum:\n","        idx = 2 * idx\n","      else:\n","        prefixsum -= self._value[2 * idx]\n","        idx = 2 * idx + 1\n","    return idx - self._capacity #???\n","\n","# Min线段树\n","class MinSegmentTree(SegmentTree):\n","\n","  def __init__(self, capacity):\n","    # 实际上不用Min树也行，直接对ER池的线段树求min。\n","    super(MinSegmentTree, self).__init__(capacity=capacity, operation=min, neutral_element=float('inf'))\n","\n","  def min(self, start=0, end=None):\n","    \"\"\"\n","    返回最小的arr[i]\n","    \"\"\"\n","    return super(MinSegmentTree, self).reduce(start, end)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i8R7rBo6ug50","colab_type":"text"},"source":["### **Experience ReplayBuffer**"]},{"cell_type":"code","metadata":{"id":"yv747O0Yup4a","colab_type":"code","colab":{}},"source":["class ReplayBuffer:\n","\n","  def __init__(self, size):\n","    self._storage = []\n","    self._maxsize = size\n","    self._next_idx = 0\n","\n","  def __len__(self):\n","    return len(self._storage)\n","\n","  def add(self, *args):\n","    if self._next_idx >= len(self._storage):\n","      self._storage.append(args)\n","    else:\n","      self._storage[self._next_idx] = args\n","    self._next_idx = (self._next_idx + 1) % self._maxsize\n","\n","  def _encode_sample(self, idxes):\n","    b_o, b_a, b_r, b_o_, b_d = [], [], [], [], []\n","    for i in idxes:\n","      o, a, r, o_, d = self._storage[i]\n","      b_o.append(o)\n","      b_a.append(a)\n","      b_r.append(r)\n","      b_o_.append(o_)\n","      b_d.append(d)\n","    return (\n","        np.stack(b_o).astype('float32') * ob_scale,\n","        np.stack(b_a).astype('int32'),\n","        np.stack(b_r).astype('float32'),\n","        np.stack(b_o_).astype('float32') * ob_scale,\n","        np.stack(b_d).astype('bool'),\n","    )\n","\n","  def sample(self, batch_size):\n","    indexes = range(len(self._storage))\n","    idxes = [random.choice(indexes) for _ in range(batch_size)]\n","    return self._encode_sample(idxes)\n","\n","# prioritized ER\n","class PrioritizedReplayBuffer(ReplayBuffer):\n","\n","  def __init__(self, size, alpha, beta):\n","    \"\"\"\n","    alpha: 0=不优先，1=完全优先\n","    \"\"\"\n","    super(PrioritizedReplayBuffer, self).__init__(size)\n","    assert alpha >= 0\n","    self._alpha = alpha\n","  \n","    it_capacity = 1\n","    while it_capacity < size:\n","      it_capacity *= 2\n","\n","    self._it_sum = SumSegmentTree(it_capacity)\n","    self._it_min = MinSegmentTree(it_capacity)\n","    self._max_priority = 1.0\n","    self.beta = beta\n","\n","  def add(self, *args):\n","    idx = self._next_idx\n","    super().add(*args)\n","    # 新加入的数据，给它最大的优先权，防止新数据不会被学习。 \n","    self._it_sum[idx] = self._max_priority**self._alpha\n","    self._it_min[idx] = self._max_priority**self._alpha\n","\n","  def _sample_proportinal(self, batch_size):\n","    res = []\n","    p_total = self._it_sum.sum(0, len(self._storage) - 1)\n","    every_range_len = p_total / batch_size\n","    for i in range(batch_size):\n","      mass = random.random() * every_range_len + i * every_range_len\n","      idx = self._it_sum.find_prefixsum_idx(mass)\n","      res.append(idx)\n","    return res\n","\n","  def sample(self, batch_size):\n","    idxes = self._sample_proportinal(batch_size)\n","\n","    it_sum = self._it_sum.sum()\n","    p_min = self._it_min.min() / it_sum # p_min 是为了计算 w_max\n","    max_weight = (p_min * len(self._storage))**(-self.beta) # w_max 是为了scale w(i) 见公式\n","\n","    p_samples = np.asarray([self._it_sum[idx] for idx in idxes]) / it_sum # 求p(i)\n","    weights = (p_samples * len(self._storage))**(-self.beta) / max_weight # 求w(i)\n","    encoded_sample = self._encode_sample(idxes)\n","    return encoded_sample + (weights, idxes)\n","\n","  def update_priorities(self, idxes, priorities):\n","    assert len(idxes) == len(priorities)\n","    for idx, priority in zip(idxes, priorities):\n","      assert priority > 0\n","      assert 0 <= idx < len(self._storage)\n","      self._it_sum[idx] = priority**self._alpha\n","      self._it_min[idx] = priority**self._alpha\n","\n","      self._max_priority = max(self._max_priority, priority)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xpCcuNHmCxmu","colab_type":"text"},"source":["### **Utils**"]},{"cell_type":"code","metadata":{"id":"I_OodosxDA2t","colab_type":"code","colab":{}},"source":["def huber_loss(x):\n","  return tf.where(tf.abs(x) < 1, tf.square(x) * 0.5, tf.abs(x) - 0.5)\n","\n","def sync(net, net_tar):\n","  for var, var_tar in zip(net.trainable_weights, net_tar.trainable_weights):\n","    var_tar.assign(var)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GdOfLRFyESDO","colab_type":"text"},"source":["### **训练**"]},{"cell_type":"code","metadata":{"id":"SiHqSS27ETwM","colab_type":"code","colab":{}},"source":["# train\n","qnet = MLP('q') if qnet_type == 'MLP' else CNN('q')\n","qnet.train()\n","trainable_weights = qnet.trainable_weights\n","targetqnet = MLP('targetq') if qnet_type == 'MLP' else CNN('targetq')\n","targetqnet.infer()\n","sync(qnet, targetqnet)\n","optimizer = tf.optimizers.Adam(learning_rate=lr)\n","\n","'''\n","这个buffer的线段树是有2n个点的，结构是完全二叉树，前n-1个点是后n个点的sum，第0个点不用，实际访问数是访问后n个数，\n","寻找数的时候从1开始，依次*2 或*2+1 访问子节点。\n","'''\n","buffer = PrioritizedReplayBuffer(buffer_size, prioritized_replay_alpha, prioritized_replay_beta0)\n","\n","o = env.reset()\n","nepisode = 0\n","t = time.time()\n","for i in range(1, number_timesteps + 1):\n","  eps = epsilon(i)\n","  buffer.beta += (1 - prioritized_replay_beta0) / number_timesteps\n","  \n","  # 选择动作\n","  if random.random() < eps:\n","    a = int(random.random() * out_dim)\n","  else:\n","    obv = np.expand_dims(o, 0).astype('float32') * ob_scale\n","    a = qnet(obv).numpy().argmax(1)[0]\n","\n","  # 执行动作，保存经验数据\n","  o_, r, done, info = env.step(a)\n","  buffer.add(o, a, r, o_, done)\n","\n","  if i >= warm_start:\n","    # 延迟更新target\n","    if i % target_q_update_freq == 0:\n","      sync(qnet, targetqnet)\n","      \n","      if i % 5000 == 0:\n","        path = os.path.join('model/', '{}.npz'.format(i))\n","        tl.files.save_npz(qnet.trainable_weights, name=path)\n","\n","    # sample数据\n","    b_o, b_a, b_r, b_o_, b_d, weights, idxs = buffer.sample(batch_size)\n","\n","    #q' 估计\n","    b_q_ = (1 - b_d) * tf.reduce_max(targetqnet(b_o_), 1)\n","\n","    # loss\n","    with tf.GradientTape() as q_tape:\n","      b_q = tf.reduce_sum(qnet(b_o) * tf.one_hot(b_a, out_dim), 1)\n","      abs_td_error = tf.abs(b_q - (b_r + reward_gamma * b_q_))\n","      priorities = np.clip(abs_td_error.numpy(), 1e-6, None)\n","      buffer.update_priorities(idxs, priorities)\n","      loss = tf.reduce_mean(weights * huber_loss(abs_td_error))\n","\n","    q_grad = q_tape.gradient(loss, trainable_weights)\n","    optimizer.apply_gradients(zip(q_grad, trainable_weights))\n","\n","  if done:\n","    o = env.reset()\n","  else:\n","    o = o_\n","\n","  # episode in info is real (unwrapped) message ???\n","  if info.get('episode'):\n","    nepisode += 1\n","    reward, length = info['episode']['r'], info['episode']['l']\n","    fps = int(length / (time.time() - t))\n","    print(\n","        'Time steps fo far:{}, episode so fa:{}, episode reward:{:.4f}, episode length:{}, FPS:{}'\\\n","        .format(i, nepisode, reward, length, fps)\n","    )\n","    t = time.time()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_zbcf_BDEUTP","colab_type":"text"},"source":["### **测试**"]},{"cell_type":"code","metadata":{"id":"WF7pQBi9EWiq","colab_type":"code","colab":{}},"source":["# test\n","qnet = MLP('q_t0') if qnet_type == 'MLP' else CNN('q_t0')\n","# tl.files.load_and_assign_npz(name='model/{}.npz'.format(20800))\n","tl.files.load_and_assign_npz(name='model/495000.npz', network=qnet)\n","qnet.eval()\n","\n","nepisode = 0\n","o = env.reset()\n","for i in range(1, number_timesteps + 1):\n","  # env.render()\n","  obv = np.expand_dims(o, 0).astype('float32') * ob_scale\n","  a = qnet(obv).numpy().argmax(1)[0]\n","   \n","  o_, r, done, info = env.step(a)\n","\n","  if done:\n","    o = env.reset()\n","  else:\n","    o = o_\n","  \n","  # ???\n","  if info.get('episode'):\n","    nepisode += 1\n","    reward, length = info['episode']['r'], info['episode']['l']\n","    print(\n","        'Time steps so fa:{}, episode so far:{}, episode reward:{:.4f}, episode length:{}'\\\n","        .format(i, nepisode, reward, length)\n","    )"],"execution_count":0,"outputs":[]}]}